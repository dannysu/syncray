#!/usr/bin/env python

import os
import shutil
import sys
import subprocess
import json
import hashlib
import argparse
import re
import getpass
from logging import error

prog = 'csync'
tmp_dir = "/tmp/.csync"

def s3_download(remote, local):
    proc = subprocess.Popen(['s3cmd', 'get', '--force', remote, local], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return proc.communicate()

def s3_upload(local, remote):
    proc = subprocess.Popen(['s3cmd', 'put', local, remote], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return proc.communicate()

def s3_delete(remote):
    proc = subprocess.Popen(['s3cmd', 'del', remote], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return proc.communicate()

def s3_md5(remote):
    proc = subprocess.Popen(['s3cmd', 'info', remote], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    output, errors = proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError("Failed to get info for " + remote)
    
    m = re.search('MD5 sum: *([a-z0-9]*)', output)
    return m.group(1)

def manta_download(remote, local):
    remote = remote.replace(" ", "%20")
    proc = subprocess.Popen(['mget', '-o', local, remote], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return proc.communicate()

def manta_upload(local, remote):
    dirname = os.path.dirname(remote)

    dirname = dirname.replace(" ", "%20")
    proc = subprocess.Popen(['mmkdir', '-p', dirname], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    output, errors = proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError("Failed to mmkdir -p " + dirname)

    remote = remote.replace(" ", "%20")
    proc = subprocess.Popen(['mput', '-c', '1', '-f', local, remote], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return proc.communicate()

def manta_delete(remote):
    remote = remote.replace(" ", "%20")
    proc = subprocess.Popen(['mrm', remote], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return proc.communicate()

def manta_md5(remote):
    remote = remote.replace(" ", "%20")
    proc = subprocess.Popen(['mmd5', remote], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    output, errors = proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError("Failed to get info for " + remote)
    
    m = re.search('^([a-z0-9]*) ', output)
    return m.group(1)

def encrypt(decrypted, encrypted, passphrase):
    data = {"output": encrypted, "input": decrypted}
    gpg_encrypt = 'gpg -c --cipher-algo AES256 --no-verbose --no-use-agent --batch --yes --passphrase-fd 0 -o %(output)s %(input)s'
    parts = gpg_encrypt.split(" ")
    command = []
    for part in parts:
        command.append(part % data)
    proc = subprocess.Popen(command, stdin = subprocess.PIPE, stdout = subprocess.PIPE, stderr = subprocess.PIPE)
    output, errors = proc.communicate(passphrase + "\n")
    if proc.returncode != 0:
        print errors
        raise RuntimeError("Failed to encrypt " + decrypted)

def decrypt(encrypted, decrypted, passphrase):
    data = {"output": decrypted, "input": encrypted}
    gpg_decrypt = 'gpg -d --cipher-algo AES256 --no-verbose --no-use-agent --batch --yes --passphrase-fd 0 -o %(output)s %(input)s'
    parts = gpg_decrypt.split(" ")
    command = []
    for part in parts:
        command.append(part % data)
    proc = subprocess.Popen(command, stdin = subprocess.PIPE, stdout = subprocess.PIPE, stderr = subprocess.PIPE)
    output, errors = proc.communicate(passphrase + "\n")
    if proc.returncode != 0:
        print errors
        raise RuntimeError("Failed to decrypt " + encrypted)

# Calculates the MD5 of a file
def md5(path):
    m = hashlib.md5()

    with open(path,'rb') as f:
        while True:
            chunk = f.read(8192)
            if not chunk: break
            m.update(chunk)

    return m.hexdigest()

def move(src, dst):
    dirname = os.path.dirname(dst)
    try:
        os.makedirs(dirname)
    except OSError:
        pass
    shutil.move(src, dst)

def list(directory):
    result = []
    for (path, dirs, files) in os.walk(directory):
        for filename in files:
            result.append(path + '/' + filename)
    return result

def download_metadata(bucket, directory, download, passphrase):
    remote = bucket + '/.csync'
    tmp_encrypt = tmp_dir + '/' + directory + '.csync.encrypt'
    tmp_decrypt = tmp_dir + '/' + directory + '.csync.decrypt'
    local = tmp_dir + '/' + directory + '.csync'

    output, errors = download(remote, tmp_encrypt)

    if "404 (Not Found)" in errors or "ResourceNotFoundError" in errors:
        # No metadata found for the directory to be backed up
        metadata = {}
    else:
        decrypt(tmp_encrypt, tmp_decrypt, passphrase)
        move(tmp_decrypt, local)

        f = open(local)
        metadata = json.loads(f.read())
        f.close()

    os.remove(tmp_encrypt)

    return metadata

def upload_metadata(bucket, directory, metadata, upload, passphrase):
    remote = bucket + '/.csync'
    tmp_encrypt = tmp_dir + '/' + directory + '.csync.encrypt'
    local = tmp_dir + '/' + directory + '.csync'

    # Save updated metadata file to disk
    output = json.dumps(metadata)
    f = open(local, "w")
    f.write(output)
    f.close()

    # Encrypt it
    encrypt(local, tmp_encrypt, passphrase)

    output, errors = upload(tmp_encrypt, remote)
    if errors != "":
        raise RuntimeError("Failed to update metadata")

    os.remove(tmp_encrypt)

def download_file(bucket, directory, path, entry, download, passphrase):
    if len(entry['files']) == 1:
        file_entry = entry['files'][0]
        remote = bucket + '/' + file_entry['path']
        tmp_encrypt = tmp_dir + '/' + os.path.basename(path) + '.encrypt'
        tmp_decrypt = tmp_dir + '/' + os.path.basename(path) + '.decrypt'
        local = directory + '/' + path

        output, errors = download(remote, tmp_encrypt)
        if errors != "":
            raise RuntimeError("Failed to download file " + local)

        decrypt(tmp_encrypt, tmp_decrypt, passphrase)
        move(tmp_decrypt, local)

        os.remove(tmp_encrypt)

        return

    cat_cmd = ['cat']
    for file_entry in entry['files']:
        remote = bucket + '/' + file_entry['path']
        tmp_encrypt = tmp_dir + '/' + os.path.basename(file_entry['path']) + '.encrypt'
        tmp_decrypt = tmp_dir + '/' + os.path.basename(file_entry['path']) + '.decrypt'
        local = tmp_dir + '/' + os.path.basename(file_entry['path'])

        output, errors = download(remote, tmp_encrypt)
        if errors != "":
            raise RuntimeError("Failed to download file " + local)
        
        decrypt(tmp_encrypt, tmp_decrypt, passphrase)
        move(tmp_decrypt, local)

        cat_cmd.append(local)

        os.remove(tmp_encrypt)

    local = open(directory + '/' + path, 'w')
    proc = subprocess.Popen(cat_cmd, stdout=local, stderr=subprocess.PIPE)
    output, errors = proc.communicate()
    if errors != "":
        raise RuntimeError("Failed to concatenate files for " + directory + '/' + path)

    local.close()

def upload_file(bucket, directory, path, upload, passphrase):
    statinfo = os.stat(path)

    pending_files = []

    # Split large files into smaller chunks
    chunk_size = 5
    if statinfo.st_size >= chunk_size * 1024 * 1024:
        dirname = os.path.dirname(path)
        filename = os.path.basename(path)
        proc = subprocess.Popen(['split', '-b' + chunk_size + 'm', path, tmp_dir + '/' + filename + '-'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        output, errors = proc.communicate()
        if errors != "":
            raise RuntimeError("Failed to split file " + path)

        for (split_path, dirs, files) in os.walk(tmp_dir):
            for file in files:
                if file.startswith(filename + '-'):
                    md5hash = md5(tmp_dir + '/' + file)
                    pending_files.append({
                        "path": dirname[len(directory)+1:] + '/' + file,
                        "orig_md5": md5hash,
                        "tmp_path": tmp_dir + '/' + file
                    })
    else:
        pending_files.append({
            "path": path[len(directory)+1:],
            "orig_md5": md5(path),
            "tmp_path": path
        })

    for file_entry in pending_files:
        tmp_path = file_entry['tmp_path']
        tmp_encrypt = tmp_dir + '/' + 'tmp.encrypt'
        file_path = file_entry['path']

        encrypt(tmp_path, tmp_encrypt, passphrase)

        if file_path.startswith('/'):
            remote = bucket + file_path
        else:
            remote = bucket + '/' + file_path

        output, errors = upload(tmp_encrypt, remote)
        if errors != "":
            print errors
            raise RuntimeError("Failed to upload file " + tmp_path)

        file_entry['encrypted_md5'] = md5(tmp_encrypt)

        os.remove(tmp_encrypt)

        file_entry.pop('tmp_path')

    return pending_files

def backup(bucket, rel_dir, mode, verbose, verify, passphrase, download, upload, delete, remote_md5):
    directory = os.path.abspath(rel_dir)
    basename = os.path.basename(directory)

    if verbose:
        print 'Backing up ' + directory + ' to ' + bucket

    # Obtain metadata containing sync state from S3
    if verbose:
        print 'Download metadata'
    metadata = download_metadata(bucket, basename, download, passphrase)

    # Go through each file in directory to find what changed
    if verbose:
        print 'Find changes'
    pending = []
    files = list(directory)
    for path in files:
        key = path[len(directory)+1:]
        if key in metadata:
            # file is in metadata, so check to see if it has changed
            md5hash = md5(path)
            if metadata[key]["orig_md5"] != md5hash:
                pending.append({"path": path, "orig_md5": md5hash})
            elif verify:
                for part in metadata[key]['files']:
                    expected_md5 = part['encrypted_md5']
                    actual_md5 = remote_md5(bucket + '/' + part['path'])
                    if expected_md5 != actual_md5:
                        pending.append({"path": path, "orig_md5": md5hash})
                        break
        else:
            # file is not in metadata, so that means file is not in remote
            pending.append({"path": path, "orig_md5": md5(path)})

    # Go through each pending file, encrypt and upload them to S3, then update metadata
    if verbose:
        print 'Upload changes'
    count = 0
    total = len(pending)
    for change in pending:
        count += 1
        if verbose:
            sys.stdout.write(str(count) + " of " + str(total))
            sys.stdout.flush()

        path = change['path']
        orig_md5 = change['orig_md5']

        encrypted_files = upload_file(bucket, directory, path, upload, passphrase)

        metadata[path[len(directory)+1:]] = {"orig_md5": orig_md5, "files": encrypted_files}
        upload_metadata(bucket, basename, metadata, upload, passphrase)

        if verbose:
            sys.stdout.write(" " + unichr(10003) + "\n")

    # If we're in Echo mode, then also delete on remote anything already gone on local
    if mode == 'e':
        remove = []
        for key in metadata:
            if not os.path.exists(directory + '/' + key):
                remove.append(key)

        for key in remove:
            delete(bucket + '/' + key)
            metadata.pop(key)
            upload_metadata(bucket, basename, metadata, upload, passphrase)

    if verbose:
        print 'Done!'

def restore(bucket, rel_dir, verbose, passphrase, download):
    directory = os.path.abspath(rel_dir)
    basename = os.path.basename(directory)

    if verbose:
        print 'Restoring ' + bucket + ' to ' + directory

    # Obtain metadata containing sync state from S3
    if verbose:
        print 'Download metadata'
    metadata = download_metadata(bucket, basename, download, passphrase)

    if verbose:
        print 'Download files'
    count = 0
    total = len(metadata.keys())
    for file in metadata:
        count += 1
        if verbose:
            sys.stdout.write(str(count) + " of " + str(total))
            sys.stdout.flush()

        path = directory + '/' + file
        if os.path.exists(path):
            md5hash = md5(path)
            if md5hash != metadata[file]['orig_md5']:
                download_file(bucket, directory, file, metadata[file], download, passphrase)
        else:
            download_file(bucket, directory, file, metadata[file], download, passphrase)

        if verbose:
            sys.stdout.write(" " + unichr(10003) + "\n")

    if verbose:
        print 'Done!'

def main():
    description = prog + """ is a tool for synchronizing folders and encrypt
                         them to cloud storage encrypted such as Amazon S3 and
                         Joyent Manta."""
    parser = argparse.ArgumentParser(description = description,
            prog = prog)

    parser.add_argument('-s', nargs='?', default='s3',
            metavar='service',
            choices=['s3', 'manta'],
            dest='service',
            help='cloud storage to use {%(choices)s} (default: %(default)s)')

    parser.add_argument('-m', nargs='?', default='contribute',
            metavar='mode',
            choices=['contribute', 'echo'],
            dest='mode',
            help="""sync mode to use {%(choices)s}. 'contribute' copies only
                 from local to remote, no deletes. 'echo' replicates changed
                 files and deletes to remote. (default: %(default)s)""")

    parser.add_argument('--verbose', dest='verbose', action='store_true')
    parser.add_argument('--verify', dest='verify', action='store_true',
            help="""verify remote files' md5 against metadata and resync if
                 there is a mismatch""")

    parser.add_argument('-p', nargs='?', metavar='passphrase', dest='passphrase',
            help="set passphrase for encryption so you don't have to type it in")

    parser.add_argument('action', nargs=1,
            choices=['backup', 'restore'],
            help='backup or restore data')

    remote_help = """s3 bucket (s3://bucket-name/folder) or Manta path
                  (/$MANTA_USER/stor/folder)"""
    parser.add_argument('remote', nargs=1, help=remote_help)

    parser.add_argument('local', nargs=1,
            help="directory on local computer")

    args = parser.parse_args()

    action = args.action[0]
    remote = args.remote[0]
    local = args.local[0]
    service = args.service[0]
    mode = args.mode[0]
    passphrase = args.passphrase
    verbose = args.verbose
    verify = args.verify

    if passphrase == None:
        passphrase = getpass.getpass("Enter passphrase to encrypt your data with: ")

    try:
        os.mkdir(tmp_dir)
    except OSError:
        pass

    if service == 's':
        download = s3_download
        upload = s3_upload
        delete = s3_delete
        remote_md5 = s3_md5
    else:
        download = manta_download
        upload = manta_upload
        delete = manta_delete
        remote_md5 = manta_md5

    if action == 'backup':
        backup(remote, local, mode, verbose, verify, passphrase, download, upload, delete, remote_md5)
    elif action == "restore":
        restore(remote, local, verbose, passphrase, download)

    shutil.rmtree(tmp_dir)

if __name__ == '__main__':
    try:
        main()
        sys.exit(0)

    except SystemExit, e:
        sys.exit(e.code)

    except KeyboardInterrupt:
        sys.exit(1)

    except Exception, e:
        error(u"Unknown problem: %s" % e)
        sys.exit(1)
